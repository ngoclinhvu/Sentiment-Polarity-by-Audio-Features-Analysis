{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1SHg0oR7Ih9WUV7EPmB83dgYG9jS8uQM9","authorship_tag":"ABX9TyODjUSX33lFj9a0FhbaLWeC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### *I - Design a feedforward deep neural network (DNN) which consists of **three** hidden layers of 128 neurons each with ReLU activation function, and an output layer with sigmoid activation function. Apply dropout of probability **0.2** to each of the hidden layers.*"],"metadata":{"id":"Sis1PahLWzH6"}},{"cell_type":"code","source":["import tqdm\n","import time\n","import random\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","import torch\n","from torch import nn\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","from scipy.io import wavfile as wav\n","\n","from sklearn import preprocessing\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n","\n","from common_utils import set_seed\n","\n","# setting seed\n","set_seed()"],"metadata":{"id":"7BxHZho_XOXa","executionInfo":{"status":"ok","timestamp":1739033613115,"user_tz":-480,"elapsed":15906,"user":{"displayName":"Ngọc Linh","userId":"14631386221920842847"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["1. Define the model class."],"metadata":{"id":"7RNlzeTwXQ4K"}},{"cell_type":"code","source":["class MLP(nn.Module):\n","\n","    def __init__(self, no_features, no_hidden, no_labels):\n","        super().__init__()\n","        self.mlp_stack = nn.Sequential(\n","            nn.Linear(no_features, no_hidden),\n","            nn.ReLU(),\n","            nn.Dropout(p=0.2),\n","            nn.Linear(no_hidden, no_hidden),\n","            nn.ReLU(),\n","            nn.Dropout(p=0.2),\n","            nn.Linear(no_hidden, no_hidden),\n","            nn.ReLU(),\n","            nn.Dropout(p=0.2),\n","            nn.Linear(no_hidden, no_labels),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        return self.mlp_stack(x)"],"metadata":{"id":"mAwu2cUEXdbs","executionInfo":{"status":"ok","timestamp":1739033620298,"user_tz":-480,"elapsed":12,"user":{"displayName":"Ngọc Linh","userId":"14631386221920842847"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## *II - Divide the dataset into a 80:20 ratio for training and testing. Use **appropriate** scaling of input features. We solely assume that there are only two datasets here: training & test.*"],"metadata":{"id":"q-wcPpqSXiJ7"}},{"cell_type":"markdown","source":["2. Split the dataset and do preprocessing."],"metadata":{"id":"VpUJ6lBhXtTM"}},{"cell_type":"code","source":["from common_utils import split_dataset, preprocess_dataset\n","\n","def preprocess(df):\n","    columns_to_drop = ['filename', 'label']\n","    test_size = 0.2\n","    random_state = 42\n","\n","    X_train, y_train, X_test, y_test = split_dataset(df, columns_to_drop, test_size, random_state)\n","\n","    X_train_scaled, X_test_scaled = preprocess_dataset(X_train, X_test)\n","\n","    X_train_scaled = torch.tensor(X_train_scaled, dtype = torch.float32)\n","    y_train = torch.tensor(y_train, dtype = torch.float32)\n","    X_test_scaled = torch.tensor(X_test_scaled, dtype = torch.float32)\n","    y_test = torch.tensor(y_test, dtype = torch.float32)\n","\n","    return X_train_scaled, y_train, X_test_scaled, y_test\n","\n","df = pd.read_csv('/content/drive/MyDrive/a - csv file/simplified.csv')\n","df['label'] = df['filename'].str.split('_').str[-2]\n","\n","X_train_scaled, y_train, X_test_scaled, y_test = preprocess(df)"],"metadata":{"id":"9N3ezu-kXujC","executionInfo":{"status":"ok","timestamp":1739033627154,"user_tz":-480,"elapsed":1406,"user":{"displayName":"Ngọc Linh","userId":"14631386221920842847"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## *III - Use the training dataset to train the model for 100 epochs. Use a mini-batch gradient descent with **‘Adam’** optimizer with learning rate of **0.001**, and **batch size = 128**. Implement early stopping with patience of **3**.*"],"metadata":{"id":"QxLKcC_zXzTR"}},{"cell_type":"markdown","source":["3. Define a Pytorch Dataset and Dataloaders.  "],"metadata":{"id":"P6qwIDlmX5Mj"}},{"cell_type":"code","source":["class CustomDataset(Dataset):\n","    def __init__(self, X, y):\n","      self.X = X\n","      self.y = y\n","\n","    def __len__(self):\n","      return len(self.X)\n","\n","    def __getitem__(self, idx):\n","      return self.X[idx], self.y[idx]\n","\n","\n","\n","def initialise_loaders(X_train_scaled, y_train, X_test_scaled, y_test):\n","    train_set = CustomDataset(X_train_scaled, y_train)\n","    test_set = CustomDataset(X_test_scaled, y_test)\n","\n","    train_dataloader = DataLoader(train_set, batch_size = 128, shuffle = True)\n","    test_dataloader = DataLoader(test_set, batch_size = 128, shuffle = True)\n","\n","    return train_dataloader, test_dataloader\n","\n","\n","\n","train_dataloader, test_dataloader = initialise_loaders(X_train_scaled, y_train, X_test_scaled, y_test)"],"metadata":{"id":"w8paKwJ_X6yH","executionInfo":{"status":"ok","timestamp":1739033630813,"user_tz":-480,"elapsed":17,"user":{"displayName":"Ngọc Linh","userId":"14631386221920842847"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Define Early Stopping class\n","class EarlyStopping:\n","    def __init__(self, patience, delta):\n","        \"\"\"\n","        :param patience: How many epochs to wait for improvement\n","        :param delta: Minimum change to qualify as an improvement\n","        \"\"\"\n","        self.patience = patience\n","        self.delta = delta\n","        self.best_loss = None\n","        self.counter = 0\n","        self.early_stop = False\n","\n","    def __call__(self, val_loss):\n","        if self.best_loss is None:\n","            self.best_loss = val_loss\n","        elif val_loss < self.best_loss - self.delta:\n","            self.best_loss = val_loss\n","            self.counter = 0  # Reset the counter if there's an improvement\n","        else:\n","            self.counter += 1\n","\n","        # Stop the training if patience is exceeded\n","        if self.counter >= self.patience:\n","            self.early_stop = True\n","\n","\n","\n","# Initialize early stopping object\n","early_stopping = EarlyStopping(patience=5, delta=0.001)"],"metadata":{"id":"QA0ZAyqn9dKu","executionInfo":{"status":"ok","timestamp":1739036120116,"user_tz":-480,"elapsed":40,"user":{"displayName":"Ngọc Linh","userId":"14631386221920842847"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["4. Next, define the model, optimizer and loss function."],"metadata":{"id":"l5qolVfkYBXX"}},{"cell_type":"code","source":["model = MLP(no_features = X_train_scaled.shape[1], no_hidden = 128, no_labels = 1)\n","optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n","loss_fn = nn.BCELoss()"],"metadata":{"id":"8TtAwkBdYDKT","executionInfo":{"status":"ok","timestamp":1739033642713,"user_tz":-480,"elapsed":5437,"user":{"displayName":"Ngọc Linh","userId":"14631386221920842847"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["5. Train model for 100 epochs. Record down train and test accuracies. Implement early stopping."],"metadata":{"id":"276ZJjbmYFxJ"}},{"cell_type":"code","source":["num_epochs = 100\n","\n","for epoch in range(num_epochs):\n","\n","    model.train()\n","    correct_train_predictions = 0\n","\n","    for batch_index, (X_train_scaled, y_train) in enumerate(train_dataloader):\n","        # Forward pass\n","        optimizer.zero_grad()\n","        y_train_predicted = model(X_train_scaled)\n","        loss = loss_fn(y_train_predicted, y_train.unsqueeze(1))\n","\n","        # Backward pass and optimization\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Calculate train accuracies\n","        y_train_predicted_labels = (y_train_predicted >= 0.5).float()\n","        correct_train_predictions += (y_train_predicted_labels == y_train).sum().item()\n","\n","    train_accuracy = correct_train_predictions / len(train_dataloader.dataset)\n","\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Train Accuracy: {train_accuracy:.4f}\")\n","\n","    # Validation step\n","    model.eval()\n","    total_val_loss = 0.0\n","    correct_test_predictions = 0\n","    with torch.no_grad():\n","        for X_test_scaled, y_test in test_dataloader:\n","            # Calculate predicted labels\n","            y_test_predicted = model(X_test_scaled)\n","\n","            # Calculate validation losses\n","            val_loss = loss_fn(y_test_predicted, y_test.unsqueeze(1))\n","            total_val_loss += val_loss.item()\n","\n","            # Calculate test accuracies\n","            y_test_predicted_labels = (y_test_predicted >= 0.5).float()\n","            correct_test_predictions += (y_test_predicted_labels == y_test).sum().item()\n","\n","        test_accuracy = correct_test_predictions / len(test_dataloader.dataset)\n","\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Test Accuracy: {test_accuracy:.4f}\")\n","\n","    # Check for early stopping\n","    avg_val_loss = total_val_loss / len(test_dataloader)\n","    early_stopping(avg_val_loss)\n","    if early_stopping.early_stop:\n","        print(\"Early stopping triggered, stop training.\")\n","        break"],"metadata":{"id":"asXcmJIPYJ7_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739036126749,"user_tz":-480,"elapsed":4096,"user":{"displayName":"Ngọc Linh","userId":"14631386221920842847"}},"outputId":"5294d393-e8cf-434d-89a5-bf67feace76f"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100, Train Accuracy: 64.1689\n","Epoch 1/100, Test Accuracy: 63.7264\n","Epoch 2/100, Train Accuracy: 64.2425\n","Epoch 2/100, Test Accuracy: 63.7139\n","Epoch 3/100, Train Accuracy: 64.2406\n","Epoch 3/100, Test Accuracy: 64.2421\n","Epoch 4/100, Train Accuracy: 64.2722\n","Epoch 4/100, Test Accuracy: 63.4900\n","Epoch 5/100, Train Accuracy: 64.3897\n","Epoch 5/100, Test Accuracy: 63.8118\n","Epoch 6/100, Train Accuracy: 64.3805\n","Epoch 6/100, Test Accuracy: 63.7388\n","Epoch 7/100, Train Accuracy: 64.2734\n","Epoch 7/100, Test Accuracy: 63.7090\n","Epoch 8/100, Train Accuracy: 64.1839\n","Epoch 8/100, Test Accuracy: 63.7678\n","Epoch 9/100, Train Accuracy: 64.1858\n","Epoch 9/100, Test Accuracy: 63.6982\n","Epoch 10/100, Train Accuracy: 64.1815\n","Epoch 10/100, Test Accuracy: 63.6376\n","Epoch 11/100, Train Accuracy: 64.1968\n","Epoch 11/100, Test Accuracy: 64.0307\n","Epoch 12/100, Train Accuracy: 64.2260\n","Epoch 12/100, Test Accuracy: 63.5605\n","Early stopping triggered, stop training.\n"]}]},{"cell_type":"markdown","source":["## *IV - Plot train and test accuracies and losses on training and test data against training epochs and comment on the line plots.*"],"metadata":{"id":"4iAgrBkiYKR3"}},{"cell_type":"code","source":[],"metadata":{"id":"9LZeLz2rYSRZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["6. Comment on line plots."],"metadata":{"id":"kLxxvGiHYVvg"}},{"cell_type":"code","source":["# YOUR CODE HERE\n","answer = \"\""],"metadata":{"id":"3nIpqgh6YZnh"},"execution_count":null,"outputs":[]}]}